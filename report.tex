\documentclass[specialist, substylefile = spbureport.rtx, subf,href,colorlinks=true, 12pt]{disser}

\usepackage[a4paper,
            mag=1000, includefoot,
            left=3cm, right=1.5cm, top=2cm, bottom=2cm, headsep=1cm, footskip=1cm]{geometry}
\usepackage{mathtext}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{float}
\usepackage{bbold}
\usepackage{graphicx}
\usepackage{ textcomp }
\usepackage{subcaption}
\usepackage{mathdots}
\usepackage{multirow}
\usepackage{longtable,booktabs,array}
\ifpdf\usepackage{epstopdf}\fi
\bibliographystyle{gost2008}

% Точка с запятой в качестве разделителя между номерами цитирований
%\setcitestyle{semicolon}

% Использовать полужирное начертание для векторов
\let\vec=\mathbf

% Включать подсекции в оглавление
\setcounter{tocdepth}{2}

\graphicspath{{fig/}}

\theoremstyle{definition}
\newtheorem{definition}{Определение}
\newtheorem{algorithm}{Алгоритм}
\newtheorem{remark}{Замечание}
\newtheorem{theorem}{Теорема}

%----------------------------------------------------------------


%-------------------------------
\begin{document}

%
% Титульный лист на русском языке
%
% Название организации
\institution{%
    Санкт-Петербургский государственный университет\\
    Прикладная математика и информатика
}

\title{Отчет по научно-исследовательской работе}

% Тема
\topic{Улучшение разделимости для автоматизации метода SSA}

% Автор
\author{Дудник Павел Дмитриевич}
\group{группа 19.Б04-мм}
    
% Научный руководитель
\sa       {Голяндина Нина Эдуардовна\\%
           Кафедра Статистического Моделирования}
\sastatus {к.\,ф.-м.\,н., доцент}

% Город и год
\city{Санкт-Петербург}
\date{\number\year}

\maketitle

\tableofcontents

\intro
В задачах, использующих временные ряды, часто требуется знать структуру этих рядов, разложение в сумму интерпретируемых компонент, например, для того, чтобы прогнозировать значения или заполнять пропуски. Такое разложение позволяет получить метод SSA, имеющий множество применений и описанный, например, в пособии \cite{Golyandina04}. Однако применение этого метода осложняется тем, что получение результата не является полностью автоматическим и требует визуального анализа. Также существует проблема отсутствия слабой/сильной разделимости компонент временного ряда, что не позволяет применить метод SSA. Существование этих проблем служит мотивацией для написания этой работы и проведения экспериментов.

В данной работе рассматривается проблема улучшения разделимости для автоматизации разложения временного ряда в сумму компонент, была поставлена задача создания алгоритма/нескольких алгоритмов для решения этой проблемы. Иначе говоря, алгоритм должен автоматически получать разложение в условиях недостатка разделимости компонент. В качестве базового метода, позволяющего извлечь компоненты, используется метод SSA.

В работе были предложены решения, позволяющие получить разделимость компонент временного ряда и произвести автоматическую группировку компонент, при этом решения используют модификации алгоритма SSA - IOSSA (Iterative Oblique SSA) и EOSSA (ESPRIT-based Oblique SSA). Описание необходимых для описания решений результатов (методов, определений и теорем) находится в разделе \ref{ch:1}.

Первая часть работы посвящена описаниям решений для автоматического выделения тренда, во второй части находятся эксперименты, сравнивающие эти методы.

Третья часть посвящена проблеме обобщения алгоритма EOSSA на случай кратных сигнальных корней.

\chapter{Вспомогательные результаты}
\label{ch:1}
\section{Модель временного ряда}
\begin{definition}
    ~$F_N = (f_1, \ldots, f_N)$ --- \textbf{временной ряд} длины $N$, $f_i \in \mathbb{R}$ --- наблюдение в момент времени $i$.
    
    $F_N = F_{Signal} + F_{Noise}$, $F_{Signal} = F_{Trend} + F_{Periodics}$ --- детерминированная составляющая; $F_{Trend}, F_{Periodics}, F_{Noise}$ --- временные ряды длины N, компоненты ряда $F$.
    \begin{itemize}
        \item $F_{Trend}$ --- тренд, медленно меняющаяся компонента
        \item $F_{Periodics}$ --- остаток, сумма периодических компонент
        \item $F_{Noise}$ --- шум, случайная составляющая
    \end{itemize}
\end{definition}
\section{Метод <<Гусеница>>-SSA}
\label{sec12}
\begin{algorithm}
\label{alg1}
    Входные данные: $F_N=(f_1, \ldots, f_N)$ --- временной ряд, $1<L<N$ --- длина окна, $r$ --- число компонент, группировка компонент (разбиение множества индексов).\\
    Результат: разложение ряда $F$ в сумму компонент: $F_N = \sum_{i = 1}^{r}\widetilde{\mathbb{X}}_i$.
    \begin{enumerate}
	    \item \textbf{Вложение}: $K=N-L+1$, ряд переводится в траекторную матрицу $\bm{X}=[X_1:\ldots:X_K]$, где $X_i = (f_i, \ldots, f_{i + L - 1})^{\mathrm{T}}$, $1 \leq i \leq K$.

	    \item Строится SVD (сингулярное разложение) траекторной матрицы: $\bm{X} = \sum\limits_{i=1}^d \sqrt{\lambda_i}U_iV_i^{\mathrm{T}} = \sum\limits_{i=1}^d\bm{X}_i$, $1 \leq i \leq d = rank\bm{X}$, $\sqrt{\lambda_i}$ --- сингулярные числа, $\bm{X}_i$ --- траекторная матрица элементарной компоненты (временного ряда, который соответствует одному слагаемому в сингулярном разложении).

	    \item \textbf{Группировка} \label{it:3}: $\bm{X} =  \sum\limits_{i=1}^r \widetilde{\bm{X}}_i$, где $\widetilde{\bm{X}}_i$ --- траекторная матрица компоненты, состоящей из одной или нескольких элементарных компонент, r --- число компонент.

	    \item \textbf{Диагонализация}: каждая траекторная матрица компоненты $\widetilde{\bm{X}}_i$ переводится во временной ряд $\widetilde{\mathbb{X}}_i$с помощью диагонального усреднения.
	\end{enumerate} 
	Более подробно алгоритм изложен в пособии \cite{Golyandina04}.
\end{algorithm}

\section{Разделимость}

\begin{definition}
\label{def1}
        Пусть имеется ряд $\mathbb{X} = \mathbb{X}_1 + \mathbb{X}_2$. Компоненты $\mathbb{X}_1$ и $\mathbb{X}_2$ называются слабо разделимыми, если существует такое SVD, что на этапе \ref{it:3}  алгоритма \ref{alg1} можно произвести группировку таким образом, что траекторную матрицу $\mathbf{X}$ можно представить в виде $\mathbf{X} = \mathbf{X}_1 + \mathbf{X}_2$.
\end{definition}

\begin{definition}
    Если в определении \ref{def1} представление $\mathbf{X} = \mathbf{X}_1 + \mathbf{X}_2$ можно получить при любом SVD, то компоненты $\mathbb{X}_1$ и $\mathbb{X}_2$ называются сильно разделимыми.
\end{definition}

\begin{remark}
    Если рассматривать задачу выделения компонент, то с помощью алгоритма \ref{alg1} можно получить нужное разложение только в том случае, когда компоненты сильно разделимы.
\end{remark}

\section{Разложение Фурье}
\begin{definition}
    ~Пусть $F_N=(f_1, \ldots, f_N)$ --- временной ряд, N --- его длина. Разложение Фурье для временного ряда:
    \begin{equation*} \label{eq2} \tag{1}
        f_n = c_0 + \sum\limits_{k = 1}^{\lfloor \frac{N - 1}{2}\rfloor} \sqrt{c_k^2 + s_k^2}\mathsf{cos}(\frac{2\pi nk}{N} + \phi_k) + c_{\frac{N}{2}}(-1)^k.
    \end{equation*}
\end{definition}
\begin{definition}
    ~Пусть имеется разложение \eqref{eq2}. Тогда следующая функция называется периодограммой:
    \begin{equation*}
                \Pi^f_N (\frac{k}{N}) = \frac{N}{2}
        \begin{cases}
        2c_0^2 & ,k = 0\\
        c_k^2+s_k^2 & ,0 < k < N/2\\
        2c^2_{N/2} & ,k = N/2
        \end{cases}
    \end{equation*}
\end{definition}
Частоту $\omega$ будем называть низкой, если она меньше некоторой $\omega_0 > 0$. Вкладом низких частот в ряд будем называть сумму $\sum\limits_{0 \leq \frac{k}{N} < \omega_0}\Pi_N^f(\frac{k}{N})$.

\section{Oblique SSA}

\begin{definition}
    Пусть $X, Y \in \mathbb{R}^n, \mathbf{A} \in \mathbb{R}^{n \times n}$. Векторы $X, Y$ называются $\mathbf{A}$-ортогональными, если
    \begin{equation*}
        (\mathbf{A}X, Y) =  \langle X, Y\rangle _{\mathbf{A}}.
    \end{equation*}
\end{definition}
\begin{definition}
    Будем говорить, что пара матриц $(\mathbf{L}, \mathbf{R})$ согласованы с матрицей $\mathbf{X}$, если пространство столбцов $\mathbf{L}$ содержит пространство столбцов $\mathbf{X}$ и пространство столбцов $\mathbf{R}$ содержит пространство строк $\mathbf{X}$.
\end{definition}
\begin{definition}
    Пусть пара матриц $(\mathbf{L}, \mathbf{R})$ согласованна с $\mathbf{X}$. Тогда минимальное разложение ранга $r$
    \begin{equation*}
        \mathbf{X} = \sum_{i = 1}^{r}\sigma_iP_iQ_i^{\mathrm{T}}
    \end{equation*}\\
    будем называть $(\mathbf{L}, \mathbf{R})$-SVD ( $(\mathbf{L}, \mathbf{R})$-сингулярным разложением) матрицы $\mathbf{X}$.
\end{definition}

Алгоритм построения $(\mathbf{L}, \mathbf{R})$-SVD подробно описан в разделе 3 статьи \cite{Golyandina15}.

\begin{definition}
    Пусть длина окна $L$ фиксирована. Ряды $\mathbb{X}^{(1)}$ и $\mathbb{X}^{(2)}$ называются слабо $(\mathbf{L}, \mathbf{R})$-разделимыми, если их траекторные пространства столбцов $\mathbf{L}$-ортогональны и траекторные пространства строк $\mathbf{R}$-ортогональны между собой, т.е.
    \begin{equation*}
        (\mathbf{X}^{(1)})^{\mathrm{T}}\mathbf{LX}^{(2)} = 0_{K \times K}, (\mathbf{X}^{(1)})\mathbf{R}(\mathbf{X}^{(2)})^{\mathrm{T}} = 0_{L \times L}.
    \end{equation*}

\end{definition}
    
\begin{definition}
    Ряды $\mathbb{X}^{(1)}$ и $\mathbb{X}^{(2)}$ называются сильно $(\mathbf{L}, \mathbf{R})$-разделимыми, если они слабо $(\mathbf{L}, \mathbf{R})$-разделимы и при этом наборы сингулярных чисел из SVD траекторных матриц $\mathbf{X}^{(1)}$ и $\mathbf{X}^{(2)}$ не пересекаются.
\end{definition}


\subsection{Nested Oblique SSA}
Будем рассматривать ряды конечной размерности, описанные в статье \cite{Shlemov}.
    \begin{definition}
        Ряд $\mathbb{S} = (s_1, .., s_N)$ управлется линейной рекуррентной формулой (ЛРФ), если
        \begin{equation*}
            s_{r+i} = a_1s_{r+i - 1} + a_2s_{r+i - 2} + . . . + a_rs_i
, \forall i \in 1, . . . , N - r.
        \end{equation*}
        При этом $r$ называется порядком ЛРФ.
    \end{definition}
    Для любого ряда, управляемого ЛРФ существует единственная ЛРФ минимального порядка.
    При этом если все корни характеристического полинома $\chi_{\mathbf{a}} (\mu ) = \mu^r - \sum^r_{k=1} a_k\mu^{r - k}$ различны, то элементы ряда $\mathbb{S}$ могут быть представлены в виде:
    \begin{equation*}
        s_j =\sum^r_{k=1} A_k\mu^j_k
, A_k \in \mathbb{C}.
    \end{equation*}
    Таким образом, ряд конечной размерности представим в виде
суммы экспонент (соответствующих вещественным корням характеристического полинома) и
экспоненциально-модулированных гармоник (соответствующих парам
комплексно-сопряженных корней характеристического полинома).

\begin{remark}
 Для любого ряда конечного ранга $\mathbb{X} = \mathbb{X}_1 + \mathbb{X}_2$ существуют такие матрицы $\mathbf{L}, \mathbf{R}$, что ряды $\mathbb{X}_1, \mathbb{X}_2$ ($\mathbf{L}, \mathbf{R}$)-разделимы.
\end{remark}

Это утверждение влечет за собой следующий алгоритм:

\begin{algorithm}
    В условиях раздела \ref{sec12}:
    Входные данные: траекторная матрица $\mathbf{X}$, соответствующая ряду $\mathbb{X}$ конечного ранга $r$, согласованные с ней $\mathbf{L}, \mathbf{R}$.\\
    Результат: разложение ряда $\mathbb{X} = \sum_{i = 1}^{r}\mathbb{X}_i$. 
\end{algorithm}
    \begin{enumerate}
        \item Строится $(\mathbf{L}, \mathbf{R})$-SVD матрицы $\mathbf{X}$.
        \item Группируются траекторные матрицы элементарных компонент.
        \item Производится диагональное усреднение траекторных матриц.
    \end{enumerate}
    Таким образом, результат алгоритма - разложение временного ряда, соответствующего траекторной матрице $\mathbf{X}$.
    \begin{remark}
    Nested Oblique SSA не может быть применен для реальных задач, так как матрицы $\mathbf{L}, \mathbf{R}$ определяются траекторными пространствами компонент, которые мы хотим получить в разложении, при этом эти пространства неизвестны, так как мы не обладаем знаниями о компонентах.
    \end{remark}
    Существуют алгоритмы, в которых матрицы $\mathbf{L}, \mathbf{R}$ некоторым образом находятся. Рассмотрим два таких алгоритма: IOSSA и EOSSA.
\subsection{Iterative Oblique SSA}
    IOSSA (Iterative Oblique SSA) --- это итеративная модификация Nested OSSA. 
    
    Пусть имеется траекторная матрица $\mathbf{X}$, пара матриц $(\mathbf{L}^{(0)}, \mathbf{R}^{(0)})$ инициализированная единичными матрицами и некоторое разбиение множества индексов $\{ 1,...,r\}$, где r - ранг минимального разложения матрицы $\mathbf{X}$, тогда $(\mathbf{L}^{(0)}, \mathbf{R}^{(0)})$-SVD матрицы $\mathbf{X}$ это обычное сингулярное разложение.
    \begin{algorithm}
    Входные данные: траекторная матрица $\mathbf{X}$, соответствующая ряду $\mathbb{X}$, начальная группировка.
    \\ Результат: разложение ряда $\mathbb{X} = \sum_{i = 1}^{r}\mathbb{X}_i$.\\
        На шаге $k \geq 1$:
        \begin{enumerate}
            \item Вычисляются $(\mathbf{L}^{(k)}, \mathbf{R}^{(k)})$ согласованные с $\mathbf{X}$ (используются траекторные пространства рядов, полученных в результате группировке предыдущего $(\mathbf{L}^{(k - 1)}, \mathbf{R}^{(k - 1)})$-SVD согласно разбиению множества индексов).
            \item Строится $(\mathbf{L}^{(k)}, \mathbf{R}^{(k)})$-SVD матрицы $\mathbf{X}$.
            \item Производится группировка согласно разбиению и диагональное усреднение, тем самым, получаем разложение ряда $\mathbb{X}$.
        \end{enumerate}
        Шаги повторяются до сходимости компонент.
    \end{algorithm}
    \begin{remark}
        Модификация алгоритма IOSSA, называемая модификацией с $\sigma$-коррекцией, описаная в подразделе 3.3.2 статьи \cite{Golyandina15} позволяет изменять разбиение индексов (это позволяет, например, избежать проблем при неудачном начальном разбиении) и ослабляет условия сильной разделимости. В разделе 2 используется именно эта модификация.
    \end{remark}
    
    \subsection{ESPRIT-motivated Oblique SSA}

Метод EOSSA (ESPRIT-based Oblique SSA) использует метод ESPRIT, описанный в статье \cite{Roy89}, чтобы разделять компоненты в случае недостатка разделимости компонент.

В случае различных сигнальных корней можно применить следующую теорему:

\begin{theorem}
\label{th1}
Пусть ряд $\mathbb{S}$ длины $N$ --— ряд конечной размерности r и все сигнальные корни характеристического полинома минимальной управляющей ЛРФ различны, $L > r$, $K = N - L + 1 > r$, $\mathbf{S} = \mathcal{T}_L\mathbb{S}$ --— $L$-траекторная матрица. Пусть $\mathbf{S} = \mathbf{P Q}^{\mathrm{T}}$ --— минимальное комплексное разложение матрицы $\mathbf{S}$, т.е. $\mathbf{P} \in \mathbb{R}^{L \times r}$, $\mathbf{Q} \in \mathbb{R}^{K \times r}$. \\
    \hspace*{0.5cm} Тогда:
    \begin{enumerate}
        \item Матрица $\mathbf{P}$ обладает сдвиговым свойством: $\overline{\mathbf{P}} = \underline{\mathbf{P}}\mathbf{M}$ для некоторой матрицы $\mathbf{M} \in \mathbb{R}^{r \times r}$.
        \item Собственные числа матрицы $\mathbf{M}$ совпадают с корнями х.п. $\mu_k$ и их кратностями.
        \item Пусть $\mathbf{M} = \mathbf{T}\mathsf{diag}(\mu_1, ..., \mu_r)\mathbf{T}^{-1}, \mathbf{T} \in \mathbb{C}^{r \times r}$ - спектральное разложение матрицы $\mathbf{M}$.
        Тогда $\mathbf{S} = \mathbf{\Pi \Psi}^{\mathrm{T}} = (\mathbf{PT})(\mathbf{T}^{-1}\mathbf{ Q}^{\mathrm{T}}), \mathbf{\Pi} \in \mathbb{C}^{L \times r}, \mathbf{\Psi} \in \mathbb{C}^{K \times r}$, где $\mathbf{\Pi} = \mathbf{PT}$ и $\mathbf{\Psi}^{\mathrm{T}} = \mathbf{T}^{-1}\mathbf{Q}^{\mathrm{T}}$, причем:
        \begin{itemize}
            \item $\mathbf{\Pi} = [\Pi_1: \ldots :\Pi_r], \mathbf{\Pi}_k \in \mathbb{C}^{L}$ соответствует k-ому сигнальному корню ; Матрица $\mathbf{\Pi}$ имеет Вандермондовскую структуру: $\Pi_k \propto (\mu_k, \mu_k^2, ..., \mu_k^L)$.
            
            \item $\mathbf{\Psi} = [\Psi_1: \ldots :\Psi_r], \mathbf{\Psi}_k \in \mathbb{C}^{K}$ соответствует k-ому сигнальному корню; Матрица $\mathbf{\Psi}$ имеет Вандермондовскую структуру: $\Psi_k \propto (1, \mu_k, ..., \mu_k^{K - 1})$.
        \end{itemize}
    \end{enumerate}

\end{theorem}
Таким образом, получаем разложение траекторной матрицы $\mathbf{S} = \sum^r_{k=1} \Pi_k\Psi_k^{\mathrm{T}} = \mathbf{\Pi \Psi}^{\mathrm{T}}$. 
\begin{remark}
    Матрицы $\mathbf{L}, \mathbf{R}$, которые нужны для построения $(\mathbf{L}, \mathbf{R})$-SVD, не находятся в этом алгоритме в явном виде. При этом можно показать, что $\mathbf{L} = (\mathbf{\Pi}^{\dag})^{\mathsf{T}}(\mathbf{\Pi}^{\dag})$ и $\mathbf{L} = (\mathbf{\Psi}^{\dag})^{\mathsf{T}}(\mathbf{\Psi}^{\dag})$, более подробно это утверждение рассматривается в статье \cite{Golyandina15}.
\end{remark}
Это приводит к следующему алгоритму (EOSSA):
\begin{algorithm} 
Входные данные: траекторная матрица сигнала $\mathbf{S}$, соответствующая ряду $\mathbb{S}$, $k$ - количество компонент.\\
Результат: разложение ряда $\mathbb{S} = \sum_{i = 1}^{k}\mathbb{S}_i$.\\
В условиях теоремы \ref{th1}:
\label{alg4}
    \begin{enumerate}
            \item Получаем минимальное разложение траекторной матрицы сигнала $\mathbf{S} = \mathbf{PQ}^{\mathrm{T}}$
            \item Оцениваем сдвиговую матрицу $\mathbf{M}$.
            \item Строим спектральное разложение сдвиговой матрицы $\mathbf{M} = \mathbf{T}\mathsf{diag}(\mu_1, ..., \mu_r)\mathbf{T}^{-1}$.
            \item Строим разложение $\mathbf{S} = (\mathbf{PT})(\mathbf{T}^{-1}\mathbf{Q}^{\mathrm{T}}) = \mathbf{\Pi \Psi}^{\mathrm{T}} = \sum_{k = 1}^{r}\mathbf{\Pi}_k\mathbf{\Psi}^{\mathrm{T}}_k$.
            \item Производим группировку попарно сопряженных компонент.
            \item Восстановление компонент через диагональное усреднение. 
        \end{enumerate}
\end{algorithm}
Более подробно алгоритм изложен в работе \cite{Shlemov}.
    
    
    
    
\chapter{Автоматизация выделения тренда}
\section{Формализация задачи}
Пусть имеется небольшое $\omega_0 > 0$ и $0 < T < 1$ близкое к единице, тогда будем относить к тренду компоненту временного ряда, у которой вклад низких частот больше $T$ (такой вклад назовем большим):
\begin{equation*}
    \sum\limits_{0 \leq \frac{k}{N} < \omega_0}\Pi_N^f(\frac{k}{N}) > T.
\end{equation*}

Таким образом, имея разложение ряда, например, полученное с помощью базового SSA, можно отобрать элементарные компоненты таким способом, получив тренд.

Однако при отсутствии разделимости компонент нельзя автоматически выделить тренд, поэтому можно ослабить условие ортогональности. Для этого в решениях используется алгоритм IOSSA.

Во всех решениях сначала выбирается длина окна $L$ и число компонент в сигнале $r$, применяется базовый алгоритм SSA и $r$ первых слагаемых в сингулярном разложении отбираются в траекторную матрицу сигнала. Таким образом, компоненты, соответствующие шуму, просто помещаются в остаток.
\section{Решения проблемы}
\subsection{Базовый алгоритм с автоматической группировкой}
В этом решении используется алгоритм \ref{alg1}, при этом на этапе \ref{it:3} траекторные матрицы элементарных компонент помещаются в отдельные группы, затем элементарные компоненты восстанавливаются, и применяется автоматическое выделение тренда. Таким образом, все элементарные компоненты сигнала с большим вкладом низких частот помещаются в тренд.

\begin{remark}
 Как уже было указано ранее, этот алгоритм не сможет выделить тренд в условиях недостатка разделимости.
\end{remark}

\subsection{Решение с автоматической начальной группировкой (IOSSA)}
Пусть имеется временной ряд $\mathbb{X}$. Выберем длину окна, а также количество компонент в сигнале.

В этом решении в качестве начальной группировки в одну группу помещаются элементарные компоненты сигнала с большим вкладом низких частот, в другую — остальные. Далее применяется алгоритм IOSSA. В результате получаем тренд, компоненту с периодиками и остаток.

\subsection{Решение без начальной группировки (IOSSA)}
В этом решении в качестве начальной группировки каждая элементарная компонента сигнала помещается в отдельную группу. Далее применяется алгоритм IOSSA, результат выполнения --- $r$ компонент из одной элементарной компоненты.

После этого относим к тренду компоненты с большим вкладом низких
частот. В результате получаем тренд, компоненту с периодиками и остаток.

\subsection{Решение, использующее EOSSA}
В этом решении к сигналу применяется алгоритм EOSSA, после этого применяется автоматическое выделение тренда.

\chapter{Численные эксперименты}
Сравнивались алгоритм, использующий IOSSA с фиксированной начальной группировкой (которая была найдена с помощью визуального анализа графика собственных векторов),
решение, использующее IOSSA с автоматической начальной группировкой, решение, использующее IOSSA без начальной группировки, решение, использующее алгоритм EOSSA, и решение, основанное на базовом алгоритме SSA. В экспериментах использовались временные ряды, где нет сильной разделимости тренда и компоненты с периодиками. Это было сделано с той целью, чтобы показать наглядно проблему отстутствия разделимости и сравнить методы в этих условиях.

В качестве $\omega_0$ выбрано значение $\frac{1}{24}$. Можно взять другое значение, необходимо было, чтобы $\omega_0 < \frac{1}{12}$, лучше взять значение "подальше", чтобы тренд не смешался с гармонической компонентой, которая имеет частоту $\frac{1}{12}$. Ограничивающая частота $\omega_0$ небольшая, исходя из того, как мы определили тренд.

Для порога вклада низких частот в случае начальной группировки IOSSA выбрано значение $T = 0.7$, исходя из того, что порог вклада должен быть достаточно большим, чтобы мы обнаружили компоненты, в которых больший вклад внес именно тренд при смешении, и при этом в то же время необходимо находить эти смешанные компоненты, вклад тренда в них при недостатке разделимости может быть небольшим.

Для автоматической группировки (с целью нахождения тренда) после применения IOSSA, которая используется на последнем этапе алгоритма без начальной группировки, используется большее значение порога вклада, $0.8$. Действительно, проблемы недостатка разделимости на этапе группировки в этом методе уже нет, поэтому можно брать значения порога вклада побольше.

В результатах вычислялась средняя и медианная ошибка выделения остатка (периодических компонент), эти значения примерно соответствуют средней и медианной ошибке выделения тренда. Также вычислялось среднее и медианное количество итераций для алгоритмов, использующих алгоритм IOSSA.
Код программы, где были написаны эксперименты, находится в Приложении А.

\section{Эксперимент 1}
\label{exp1}
В эксперименте был создан временной ряд $f_n , 0\leq n < N, N=101$, с функцией тренда $-0.2 e^{0.03n}$ и гармоникой $2.65 \mathsf{cos}(\frac{2\pi n}{3})$, добавлен шум $0.2 \sigma_n$, где $\sigma_n$ --- стандартный гауссовский шум.

Тренд в этом примере простой, он состоит из одной элементарной компоненты.

Согласно результатам, полученным в результате эксперимента (результаты отражены в Таблице \ref{tabular:1}), решению, использующему IOSSA без начальной группировки, потребовалось чуть большее количество итераций, по сравнению остальными решениями, использующим IOSSA. При этом можно увидеть, что у всех методов, основанных на Oblique SSA (первые 4 метода), ошибка выделения тренда и остатка примерно одинаковая. Если посмотреть на результат метода, основанного на базовом алгоритме, то можно увидеть, что ошибка выделения тренда и остатка больше, чем у других методов, на два порядка.

\begin{table}[h]
\footnotesize
\caption{Сравнение решений}
\label{tabular:1}
\begin{center}
\begin{tabular}{|c | c| c| c| c| c| c|}
\hline
 \multirow{2}{}{}& \multicolumn{2}{c|}{Выделение тренда} & \multicolumn{2}{c|}{Выделение остатка} & \multicolumn{2}{c|}{Количество итераций} \\
 \hline
 & MSE, mean & MSE, med & MSE, mean & MSE, med & mean & med  \\
\hline
no grouping & 0.0016 &  0.0013 & 0.0029 &  0.0026 & 7 & 3 \\
manual grouping &  0.0014 & 0.0011 & 0.0027 & 0.0024 & 3 & 3 \\
auto grouping &  9e-04 & 6e-04 & 0.0022 & 0.002 & 3 & 3 \\
\hline
eossa & 9e-04 & 6e-04 & 0.0022 & 0.002 & \multicolumn{2}{c|}{-} \\
basic\_ssa &  0.1756 & 0.0917 & 0.1822 & 0.0852  & \multicolumn{2}{c|}{-} \\
\hline
\end{tabular}
\end{center}
\end{table}

\section{Эксперимент 2}
\label{exp2}
В эксперименте был создан временной ряд $f_n , 0\leq n < N, N=101$, с функцией тренда $2e^{0.03n} - 0.1n - 20$ и гармониками $5.2\mathsf{cos}(\frac{2\pi n}{6} + \frac{\pi}{4})$, $5.2\mathsf{cos}(\frac{2 \pi n} {3})$,  добавлен шум $0.2 \sigma_n$, где $\sigma_n$ --- стандартный гауссовский шум.

Согласно результатам, полученным в результате эксперимента (результаты отражены в Таблице \ref{tabular:2}), решению, использующему IOSSA без начальной группировки, потребовалось большое количество итераций, на два порядка больше, чем остальным решениям, использующим IOSSA. При этом можно увидеть, что медианное количество итераций значительно меньше среднего, что говорит о некотором количестве случаев, когда сходимость затруднялась.

Средняя ошибка выделения тренда и остатка для метода, использующего IOSSA с автоматической начальной группировкой, заметно больше, чем медианная. Это говорит о некотором количестве неудачных начальных группировок. При этом медианная ошибка примерно такая же, как у других методов, решающих проблему отсутствия разделимости.

Можно отметить, что решение, использующее IOSSA без начальной группировки,и решение, использующее EOSSA, показали устойчивый результат: средние ошибки выделения примерно равны медианным.

Метод, использующий базовый метод SSA, показал большую ошибку.

\begin{table}[H]
\footnotesize
\caption{Сравнение решений}
\label{tabular:2}
\begin{center}
\begin{tabular}{|c | c| c| c| c| c| c|}
\hline
 \multirow{2}{}{}& \multicolumn{2}{c|}{Выделение тренда} & \multicolumn{2}{c|}{Выделение остатка} & \multicolumn{2}{c|}{Количество итераций} \\
 \hline
 & MSE, mean & MSE, med & MSE, mean & MSE, med & mean & med  \\
\hline
no grouping &  0.0031 & 0.0029 & 0.0054 & 0.0049 & 477 & 372 \\
manual grouping & 0.0022 & 0.0019 & 0.0046 & 0.0044 & 4 & 4 \\
auto grouping &  0.3337 & 0.0017 & 0.3268 & 0.0044 & 5 & 4 \\
\hline
eossa &  0.0019 & 0.0016 & 0.0044 & 0.0041 & \multicolumn{2}{c|}{-} \\
basic\_ssa &  5.9826 & 2.9367 & 5.9596 & 2.9348 & \multicolumn{2}{c|}{-} \\
\hline
\end{tabular}
\end{center}
\end{table}

\section{Выводы из экспериментов}
Метод, использующий базовый алгоритм SSA, показал в обоих экспериментах большую ошибку. Это неслучайно: в экспериментах не было сильной разделимости тренда и периодик, поэтому, разложение получалось неверным.

В эксперименте со сложным трендом (эксперимент \ref{exp2}) решению, использующему IOSSA без начальной группировки, потребовалось большое количество итераций для сходимости. Этот метод можно использовать для решения задачи в том случае, если устраивает большое время работы, и при этом нужна устойчивость и точность. Если же необходимо небольшое время работы, то можно использовать решение с автоматической начальной группировкой.

Также в качестве решения, автоматически выделяющего тренд, можно взять метод, использующий EOSSA. Однако существуют ограничения для применимости этого метода (несовпадение сигнальных корней). Это послужило мотивацией к модификации метода, подробно описанной в разделе \ref{ch3}.

\chapter{Обобщение алгоритма EOSSA на случай кратных сигнальных корней}
\label{ch3}
Для задачи, поставленной в начале, можно использовать алгоритм EOSSA (Алгоритм \ref{alg4}). Однако если рассматривать тренд с кратными сигнальными корнями, то EOSSA уже нельзя будет применить. Следовательно, существует необходимость в обобщении EOSSA на случай кратных сигнальных корней. Для этого сначала приведем подробное доказательство Теоремы \ref{th1}:

\begin{theorem}
Пусть ряд $\mathbb{S}$ длины $N$ — ряд конечной размерности r и все
корни $\{ \mu_k\}_{k=1}^r$ характеристического полинома минимальной управляющей ЛРФ различны, $L > r$, $K = N - L + 1 > r$, $\mathbf{S} = \mathcal{T}_L\mathbb{S}$ — $L$-траекторная матрица. Пусть $\mathbf{S} = \mathbf{PQ}^{\mathrm{T}}$ — минимальное разложение матрицы $\mathbf{S}$, т.е. $\mathbf{P} \in \mathbb{R}^{L \times r}$ и $\mathbf{Q} \in \mathbb{R}^{K \times r}$. \\
    \hspace*{0.5cm} Тогда:
    \begin{enumerate}
        \item Матрица $\mathbf{P}$ обладает сдвиговым свойством: $\overline{\mathbf{P}} = \underline{\mathbf{P}}\mathbf{M}$ для некоторой матрицы $\mathbf{M} \in \mathbb{R}^{r \times r}$.
        \item Собственные числа матрицы $\mathbf{M}$ совпадают с корнями х.п. $\mu_k$.
        \item Пусть $\mathbf{M} = \mathbf{T}$\mathsf{diag}$(\mu_1,\dots,\mu_r)\mathbf{T}^{-1}, \mathbf{T} \in \mathbb{C}^{r \times r}$ - спектральное разложение (eigen\-decomposition, EVD) матрицы $\mathbf{M}$.Тогда $\mathbf{S} = \mathbf{\Pi\Psi}^{\mathrm{T}} = (\mathbf{PT})(\mathbf{Q}(\mathbf{T}^{-1})^{\mathrm{T}})^{\mathrm{T}}, \mathbf{\Pi} \in \mathbb{C}^{L \times r}, $\\$\mathbf{\Psi} \in \mathbb{C}^{K \times r}$ - комплексное минимальное разложение матрицы $\mathbf{S}$, где матрицы $\mathbf{\Pi} = \mathbf{PT}$ и $\mathbf{\Psi} = \mathbf{Q}(\mathbf{T}^{-1})^{\mathrm{T}}$ имеют Вандермондовскую структуру: $\mathbf{\Pi} = [\Pi_1: \ldots :\Pi_r], \mathbf{\Psi} = [\Psi_1: \ldots :\Psi_r]$, где $\Pi_k \propto(\mu_k,\mu_k^2, \dots, \mu_k^L)^{\mathrm{T}}, \Psi_k \propto(1,\mu_k, \dots, \mu_k^{K - 1})^{\mathrm{T}}$.
    \end{enumerate}

\end{theorem}
\begin{proof}
Доказательство первых двух пунктов теоремы приведено в работе \cite{Huffel94}.

Доказательство п. 3. Рассмотрим разложение ряда $\mathbb{S}$ в сумму компонент в форме $s_j = \sum_{k = 1}^{r}A_k\mu_k^j$, $A_k \in \mathbb{C}$. Оно соответствует разложению траекторной матрицы $\mathbf{S} = \sum_{k = 1}^{r}\Pi_k\Psi_k^{\mathrm{T}} = \mathbf{\Pi\Psi}^{\mathrm{T}}$. Рассмотрим матрицу $\mathbf{T} \in \mathbb{C}^{r \times r}$ такую, что $\mathbf{\Pi} = \mathbf{PT}$. Такая $\mathbf{T}$ всегда существует и единственна, т.к. $\mathbf{PQ}^{\mathrm{T}} = \mathbf{\Pi\Psi}^{\mathrm{T}}$ - минимальные разложения матрицы $\mathbf{S}$, причем $\mathbf{T} = \mathbf{Q}^{\mathrm{T}}(\mathbf{\Psi}^{\mathrm{T}})^{-1}$. Заметим, что 
\begin{equation*}
   \underline{\mathbf{P}}\mathbf{T}\mathsf{diag}(\mu_1, \ldots, \mu_r)\mathbf{T}^{-1} = \underline{\mathbf{\Pi}}\mathsf{diag}(\mu_1, \ldots, \mu_r)\mathbf{T}^{-1} = \begin{pmatrix}
        c_1\mu_1& \dots& c_r\mu_r \\
        c_1\mu_1^2& \dots& c_r\mu_r^2 \\
        \vdots& \ddots& \vdots \\
        c_1\mu_1^{L - 1}& \dots& c_r\mu_r^{L - 1}
   \end{pmatrix} \cdot 
\end{equation*}
\begin{equation*}
\cdot
    \begin{pmatrix}
        \mu_1 & & & \\
        & \mu_2 & & \\
        & & \ddots & \\
        & & & \mu_r
    \end{pmatrix}
    \mathbf{T}^{-1} = \begin{pmatrix}
        c_1\mu_1^2 & c_2\mu_2^2 & \dots & c_r\mu_r^2 \\
        c_1\mu_1^3 & c_2\mu_2^3 & \dots & c_r\mu_r^3 \\
        \vdots & \vdots & \ddots & \vdots \\
        c_1\mu_1^L & c_2\mu_2^L & \dots & c_r\mu_r^L
    \end{pmatrix}
    \mathbf{T}^{-1} = \overline{\mathbf{\Pi}}\mathbf{T}^{-1} = \overline{\mathbf{P}}
\end{equation*}
Таким образом, условие выполнено и столбцы $\mathbf{T}$ - собственные вектора матрицы $\mathbf{M}$. \\
Получаем, что $\mathbf{\Psi}^{\mathrm{T}} = \mathbf{T}^{-1}\mathbf{Q}^{\mathrm{T}} = (\mathbf{Q}(\mathbf{T}^{-1})^{\mathrm{T}})^{\mathrm{T}}$, следовательно, $\mathbf{S} = (\mathbf{PT})(\mathbf{Q}(\mathbf{T}^{-1})^{\mathrm{T}})^{\mathrm{T}}$. \\
\hspace*{0.5cm} Пусть $\widetilde{\mathbf{T}} = [\alpha_1T_1: \dots :\alpha_rT_r] = \mathbf{T}\mathsf{diag}(\alpha_1, \dots ,\alpha_r), \alpha_i \in \mathbb{C}$. Тогда $\widetilde{\mathbf{T}}^{-1} = \mathbf{T}^{-1}\mathsf{diag}(\alpha_1^{-1}, \dots ,\alpha_r^{-1})$, причем $\mathbf{S} = (\mathbf{P}\widetilde{\mathbf{T}})\widetilde{\mathbf{T}}^{-1}\mathbf{Q}^{\mathrm{T}} = (\mathbf{P}\mathbf{T})\mathbf{T}^{-1}\mathbf{Q}^{\mathrm{T}}$. Таким образом, при домножении собственных векторов
на произвольные комплексные константы условие не нарушается и 3
верно для любого EVD матрицы $\mathbf{M}$.
\end{proof}

\begin{theorem}
Если исходный ряд $\mathbb{X}$ конечного ранга $r$ без шума, состоит из экспонент и экспоненциально-модулированных гармоник, то алгоритм разделяет его на экспоненты и экспоненциально-модулированные гармоники. При этом для алгоритма нет проблемы сильной и слабой разделимости.
\end{theorem}
\begin{proof}
Мы знаем, что $\mathbf{X} = \mathbf{\Pi\Psi}^{\mathrm{T}}$ и $\Pi_k \propto (\mu_k, \dots ,\mu^L_k), \Psi_k \propto (1, \mu_k, \dots ,\mu^{K-1}_k)$. Пусть 
\begin{equation*}\
    \mathbf{\Pi} = \begin{pmatrix}
        c_1\mu_1 & \dots & c_r\mu_r \\
        \vdots & \ddots & \vdots \\
        c_1\mu_1^L & \dots & c_r\mu_r^L
    \end{pmatrix}, \mathbf{\Psi}^{\mathrm{T}} = 
    \begin{pmatrix}
        h_1 & h_1\mu_1 & \dots & h_1\mu_1^{K - 1} \\
        \vdots & \vdots & \ddots & \vdots \\
        h_r & h_r\mu_r & \dots & h_r\mu_r^{K - 1}
    \end{pmatrix} \Rightarrow  \mathbb{X}_j = \sum_{i = 1}^{r}c_i h_i \mu_i^j.
\end{equation*} \\


Пусть $\mathbb{X} = \mathbb{X}^{(1)} + \mathbb{X}^{(2)}$, где $\mathbb{X}^{(1)}$ - ряд ранга $r_1$, состоящий только из экспонент, $\mathbb{X}^{(2)}$ - ряд ранга $r_2$, состоящий только из экспоненциально-модулированных гармоник, $r = r_1 + r_2, |J_1| = r_1, |J_2| = r_2$. \\
\hspace*{0.5cm}Пусть $\mathbb{X}^{(1)}_{ij}$ - это $j$-ый элемент ряда (экспоненты), соответствующего $i$-ой экспоненте, и в частности, $i$-ому сигнальному корню, $i \in J_1$. Тогда если $\mathbb{X}^{(1)}_{ij} = A_i e^{\alpha_i j}$, то $\mathbb{X}^{(1)}_{ij} = A_i\mu_i^j$, где $\mu_i = e^{\alpha_i}$. Таким образом $\mathbb{X}^{(1)}_j = \sum_{i = 1}^{r_1}A_i\mu_i^j$. Следовательно, каждой экспоненте соответствует некоторое слагаемое в представлении $\mathbb{X}_j$, причем единственное. \\
\hspace*{0.5cm} Аналогично $\mathbb{X}^{(2)}_{kj}$ - это $j$-ый элемент ряда , соответствующего $k$-ой экспоненциально-модулированной гармонике. Пусть $\mathbb{X}^{(2)}_{kj} = A_k e^{\alpha_k j}\mathsf{cos}(2\pi \omega_k j + \phi_k)$. Будем считать, что $\alpha \neq 0,\omega \in (0;\frac{1}{2}), L \geq 2, N \geq L + 1$, или $\alpha = 0, \omega < \frac{1}{2}$, таким образом ряд, соответствующий гармонике имеет ранг 2, ей соответствуют два сигнальных корня. Тогда:
\begin{equation*}
    \mathbb{X}^{(2)}_{kj} = \frac{A_k}{2}e^{\phi_k i}(e^{2\pi \omega_k i + \alpha_k}) + \frac{A_k}{2}e^{-\phi_k i}(e^{-2\pi \omega_k i + \alpha_k});
\end{equation*}
\begin{equation*}
    \mathbb{X}^{(2)}_{j} = \sum_{k = 1}^{\frac{r_2}{2}}\sum_{m = 1}^{2}\frac{A_k}{2}B_{km}\mu_{km}^{j},
\end{equation*}
где $B_{k1} = e^{\phi_k i}, B_{k2} = e^{-\phi_k i}, \mu_{k1} = e^{2\pi \omega_k i + \alpha_k}, \mu_{k2} = e^{-2\pi \omega_k i + \alpha_k}$. Следовательно, в разложении $\mathbb{X}_j$ существуют ровно два слагаемых, соответствующих гармонике, т.е. сопряженным сигнальным корням $\mu_{k1}$ и $\mu_{k2}$. \\
Таким образом, получили представление ряда в виде суммы экспонент и экспоненциально-модулированных гармоник. При этом разложение однозначно определено, в силу однозначной определенности набора сигнальных корней. Следовательно, нет проблемы сильной и слабой разделимости.
\end{proof}

Теперь перейдем к общему случаю, приведем теорему и алгоритм для случая кратных корней.

\begin{definition}
        Функция
        \begin{equation*}
            F_m[X] = \begin{cases}
            0, & m < 0 \\
            1, & m = 0 \\
            \frac{1}{m!}\prod_{i=0}^{m - 1}(X - i), & m>0
            \end{cases}
        \end{equation*}
        называется убывающим факториалом.
    \end{definition}

\begin{theorem}
\label{th4}
Пусть ряд $\mathbb{S}$ длины $N$ --— ряд конечной размерности r, n --- число различных сигнальных корней характеристического полинома минимальной управляющей ЛРФ, $L > r$, $K = N - L + 1 > r$, $\mathbf{S} = \mathcal{T}_L\mathbb{S}$ --— $L$-траекторная матрица. Пусть $\mathbf{S} = \mathbf{P\Sigma Q}^{\mathrm{T}}$ --— сингулярное разложение матрицы $\mathbf{S}$, т.е. $\mathbf{P} \in \mathbb{R}^{L \times r}$, $\mathbf{Q} \in \mathbb{R}^{K \times r}$ и $\mathbf{\Sigma} \in \mathbb{R}^{r \times r}$. \\
    \hspace*{0.5cm} Тогда:
    \begin{enumerate}
        \item Матрица $\mathbf{P}$ обладает сдвиговым свойством: $\overline{\mathbf{P}} = \underline{\mathbf{P}}\mathbf{M}$ для некоторой матрицы $\mathbf{M} \in \mathbb{R}^{r \times r}$.
        \item Собственные числа матрицы $\mathbf{M}$ и их кратности совпадают с корнями х.п. $\mu_k$ и их кратностями.
        \item Пусть $\mathbf{M} = \mathbf{TJ}\mathbf{T}^{-1}, \mathbf{T} \in \mathbb{C}^{r \times r}$ - каноническое жорданово представление матрицы $\mathbf{M}$:
        \begin{equation*}
            \mathbf{J} = \begin{pmatrix}
                    \mathbf{J}_1 & 0 & \ldots & 0\\
                    0 & \mathbf{J}_2 & \ddots & \vdots \\
                    \vdots & \ddots & \ddots & 0 \\
                    0 & \ldots & 0 & \mathbf{J}_n \\
                    \end{pmatrix},
            \mathbf{J_k} =         \begin{pmatrix}
                    \mu_k & 1 & 0 & \ldots & 0 \\
                    0 & \mu_k & 1 & \ddots & \vdots \\
                    0 & 0 & \mu_k & \ddots & 0 \\
                    \ldots & \ddots & \ddots & \ddots & 1 \\
                    0 & \ldots & 0 & 0 & \mu_k \\
                    \end{pmatrix}
        \end{equation*}
        Тогда $\mathbf{S} = \mathbf{\Pi H\Psi}^{\mathrm{T}} = (\mathbf{PT})(\mathbf{T}^{-1}\mathbf{\Sigma Q}^{\mathrm{T}}), \mathbf{\Pi} \in \mathbb{C}^{L \times r}, \mathbf{\Psi} \in \mathbb{C}^{K \times r}, \mathbf{H} \in \mathbb{C}^{r \times r}$, где $\mathbf{\Pi} = \mathbf{PT}$ и $\mathbf{H\Psi}^{\mathrm{T}} = \mathbf{T}^{-1}\mathbf{\Sigma Q}^{\mathrm{T}}$, причем:
        \begin{itemize}
            \item $\mathbf{\Pi} = [\Pi_1: \ldots :\Pi_r], \mathbf{\Pi}_k \in \mathbb{C}^{L \times M_k}$ соответствует k-ому сигнальному корню кратности $M_k$; $\mathbf{\Pi}_k[i, j] = F_j[i]\mu_k^{i - j}$, где $i = 0..L-1, j = 0..M_k-1$.
            \item Матрица $\mathbf{H}$ имеет блочно-диагональный вид:
            \begin{equation*}
                \mathbf{H} = \begin{pmatrix}
                    \mathbf{H}_1 & 0 & \ldots & 0\\
                    0 & \mathbf{H}_2 & \ddots & \vdots \\
                    \vdots & \ddots & \ddots & 0 \\
                    0 & \ldots & 0 & \mathbf{H}_n \\
                    \end{pmatrix},
            \end{equation*}
            причем $\mathbf{H_k} \in \mathbb{C}^{M_k \times M_k}$, и $\mathbf{H}_k$ верхне анти-треугольные, ганкелевы:
            \begin{equation*}
                \mathbf{H}_k = \begin{pmatrix}
                    \beta _{(k, 0)} & \beta _{(k, 1)} & \ldots & \beta _{(k, M_k - 1)}\\
                    \beta _{(k, 1)} & \iddots & \iddots & \vdots \\
                    \vdots & \iddots & \iddots & 0 \\
                    \beta _{(k, M_k - 1)} & \ldots & 0 & 0 \\
                    \end{pmatrix},
            \end{equation*}
            $\beta_{(k, p)} = \mu^{p + 1} \sum_{\alpha = 0}^{M_k - 1}K_{(p, \alpha)}c_{\alpha}$, $c_{\alpha} \in \mathbb{C},$
            \begin{equation*}
                K_{(i, j)} = \begin{cases}
                1, & i = 0 \\
                0, & i > j \\
                (i + 1)^j - \sum_{k = 0}^{M_k - 1}K_{(k, j)}c_{\alpha}, & иначе
                \end{cases}
            \end{equation*}
            
            \item $\mathbf{\Psi} = [\Psi_1: \ldots :\Psi_r], \mathbf{\Psi}_k \in \mathbb{C}^{K \times M_k}$ соответствует k-ому сигнальному корню кратности $M_k$; $\mathbf{\Psi}_k[i, j] = F_j[i]\mu_k^{i - j}$, где $i = 0..K-1, j = 0..M_k-1$.
        \end{itemize}
    \end{enumerate}

\end{theorem}
\begin{proof}
Доказательство п. 3. Рассмотрим разложение ряда $\mathbb{S}$ в сумму компонент в форме $s_j = \sum_{k = 1}^{n} \mu_k^j \sum_{p = 1}^{M_k} c_{p - 1}j^{p - 1}$, $c_m \in \mathbb{C}$. Оно соответствует разложению траекторной матрицы $\mathbf{S} = \sum_{k = 1}^{n}\mathbf{\Pi}_k\mathbf{H}_k \mathbf{\Psi}_k^{\mathrm{T}} = \mathbf{\Pi H\Psi}^{\mathrm{T}}$. Рассмотрим матрицу $\mathbf{T} \in \mathbb{C}^{r \times r}$ такую, что $\mathbf{\Pi} = \mathbf{PT}$. Такая $\mathbf{T}$ всегда существует и единственна, т.к. столбцы $\mathbf{P}$ и $\mathbf{\Pi}$ это базисы одного и того же пространства. Заметим, что 
\begin{equation*}
   \underline{\mathbf{P}}\mathbf{TJ}\mathbf{T}^{-1}
   = \underline{\mathbf{\Pi}}\mathbf{JT}^{-1},
   ( \underline{\mathbf{\Pi}}\mathbf{J})[i, j] = F_j[i + 1]\mu^{i - j + 1} = \overline{\mathbf{\Pi}}[i, j] \Rightarrow
\underline{\mathbf{\Pi}}\mathbf{JT}^{-1} =    \overline{\mathbf{\Pi}}\mathbf{T}^{-1} = \overline{\mathbf{P}}
\end{equation*}
Таким образом, условие выполнено и столбцы $\mathbf{T}$ - вектора жорданового базиса матрицы $\mathbf{M}$.
Получаем, что $\mathbf{H\Psi}^{\mathrm{T}} = \mathbf{T}^{-1}\mathbf{\Sigma Q}^{\mathrm{T}}$, следовательно, $\mathbf{S} = \mathbf{\Pi H\Psi}^{\mathrm{T}} = (\mathbf{PT})(\mathbf{T}^{-1}\mathbf{\Sigma Q}^{\mathrm{T}})$. \\
\hspace*{0.5cm} Пусть $\widetilde{\mathbf{T}} = [\alpha_1T_1: \dots :\alpha_rT_r] = \mathbf{T}\mathsf{diag}(\alpha_1, \dots ,\alpha_r), \alpha_i \in \mathbb{C}$. Тогда\\ $\widetilde{\mathbf{T}}^{-1} = \mathbf{T}^{-1}\mathsf{diag}(\alpha_1^{-1}, \dots ,\alpha_r^{-1})$, причем $\mathbf{S} = (\mathbf{P}\widetilde{\mathbf{T}})\widetilde{\mathbf{T}}^{-1}\mathbf{\Sigma Q}^{\mathrm{T}} = (\mathbf{P}\mathbf{T})\mathbf{T}^{-1}\mathbf{\Sigma Q}^{\mathrm{T}}$. Таким образом, при домножении базисных векторов
на произвольные комплексные константы условие не нарушается и 3
верно для любого канонического жорданового представления матрицы $\mathbf{M}$.
\end{proof}

С помощью этой теоремы перейдем к алгоритму:

\begin{algorithm}
Входные данные: траекторная матрица сигнала $\mathbf{S}$, соответствующая ряду $\mathbb{S}$, $n$ - количество компонент.\\
Результат: разложение ряда $\mathbb{S} = \sum_{i = 1}^{n}\mathbb{S}_i$.\\
 В условия теоремы \ref{th4}:
\begin{enumerate}
            \item Получаем сингулярное разложение траекторной матрицы сигнала $\mathbf{S} = \mathbf{P\Sigma Q}^{\mathrm{T}}$
            \item Оцениваем сдвиговую матрицу $\mathbf{M}$.
            \item Получаем каноническое жорданово представление сдвиговой матрицы $\mathbf{M} = \mathbf{TJ}\mathbf{T}^{-1}$.
            \item Строим разложение $\mathbf{S} = (\mathbf{PT})(\mathbf{T}^{-1}\mathbf{\Sigma Q}^{\mathrm{T}}) = \mathbf{\Pi H \Psi}^{\mathrm{T}} = \sum_{k = 1}^{n}\Pi_k H_k\Psi^{\mathrm{T}}_k$.
            \item Производим группировку попарно сопряженных компонент.
            \item Восстановление компонент через диагональное усреднение. 
        \end{enumerate}
\end{algorithm}

\begin{remark}
 Вычисление жорданового представления с помощью вычислительных методов неусточиво, поэтому можно получить нужные матрицы приближенно следующим образом:
 \begin{enumerate}
     \item Получить с помощью вычислительных методов спектральное разложение траекторной матрицы сигнала и произвести кластеризацию сигнальных корней.
     \item Оценить корневые подпространства, соответствующие этим корням.
 \end{enumerate}
 Таким образом, обобщение EOSSA на случай кратных корней сводится к оценке корневых подпространств.
\end{remark}

\conclusion

Таким образом, в работе были исследованы методы, позволяющие избежать проблемы отсутствия разделимости и при этом позволяющие автоматически извлекать тренд. Были проведены эксперименты для сравнения этих методов в разных примерах. Найдены положительные свойства решений, а также их недостатки.

Также алгоритм EOSSA для кратных корней был сведен к задаче поиска корневых подпространств. В будущем планируется разрешить проблему с корневыми пространствами и полностью сформулировать алгоритм.



\bibliography{refs}

\chapter{Приложение А}

\end{document}

